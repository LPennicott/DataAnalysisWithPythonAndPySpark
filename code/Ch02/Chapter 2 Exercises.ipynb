{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "942f14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, explode, lower, regexp_extract, length, greatest\n",
    "from pyspark.sql.utils import AnalysisException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ddb1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master('local[2]')\n",
    "    .config(\"spark.python.worker.reuse\", \"false\")\n",
    "    .config(\"spark.network.timeout\", \"600s\")\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"300s\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081fada0",
   "metadata": {},
   "source": [
    "## Exercise 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589d3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_2_df = spark.createDataFrame(\n",
    "    [['test', 'more test', 10_000_000_000]], ['one', 'two', 'three']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485feffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_2_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30374687",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = exo2_2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_counter = 0\n",
    "for items in columns_to_check:\n",
    "    if str(exo2_2_df.schema[items].dataType) != 'StringType()': \n",
    "        type_counter =+ 1\n",
    "\n",
    "print(type_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e6e6f",
   "metadata": {},
   "source": [
    "## Exercise 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_3_df = (\n",
    "    spark.read.text('../../data/gutenberg_books/1342-0.txt')\n",
    "    .select(length(col('value')).alias('number_of_char'))\n",
    ")\n",
    "\n",
    "exo2_3_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e4d8f7",
   "metadata": {},
   "source": [
    "## Exercise 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8952c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_4_df = spark.createDataFrame(\n",
    "    [['key', 10_000, 20_000]], ['key', 'value1', 'value2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4459499",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_4_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b560f62",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exo2_4_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnalysisException\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     exo2_4_mod \u001b[38;5;241m=\u001b[39m \u001b[43mexo2_4_df\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\n\u001b[0;32m      5\u001b[0m         col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      6\u001b[0m         greatest(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue1\u001b[39m\u001b[38;5;124m'\u001b[39m), col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue2\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     )\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AnalysisException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(err)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exo2_4_df' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "try:\n",
    "    exo2_4_mod = exo2_4_df.select(\n",
    "        col('key'),\n",
    "        greatest(col('value1'), col('value2')).alias('max_value')\n",
    "    ).select('key', 'max_value')\n",
    "except AnalysisException as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6395de",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_4_mod.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6a301",
   "metadata": {},
   "source": [
    "## Exercise 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c23f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = spark.read.text('../../data/gutenberg_books/1342-0.txt')\n",
    "\n",
    "lines = book.select(split(book.value, ' ').alias('line'))\n",
    "\n",
    "words = lines.select(explode(col('line')).alias('word'))\n",
    "\n",
    "words_lower = words.select(lower(col('word')).alias('word_lower'))\n",
    "\n",
    "words_clean = words_lower.select(\n",
    "    regexp_extract(col('word_lower'), '[a-z]*', 0).alias('word')\n",
    ")\n",
    "\n",
    "words_nonull = words_clean.where(col('word') != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa47728",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_not_is = words_nonull.where(col('word') != 'is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c244621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_longer_than_three = words_nonull.filter(\n",
    "    length(col('word')) > 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20e7a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|        word|\n",
      "+------------+\n",
      "|     project|\n",
      "|   gutenberg|\n",
      "|       ebook|\n",
      "|       pride|\n",
      "|   prejudice|\n",
      "|        jane|\n",
      "|      austen|\n",
      "|        this|\n",
      "|       ebook|\n",
      "|      anyone|\n",
      "|    anywhere|\n",
      "|        cost|\n",
      "|        with|\n",
      "|      almost|\n",
      "|restrictions|\n",
      "|  whatsoever|\n",
      "|        copy|\n",
      "|        give|\n",
      "|        away|\n",
      "|       under|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_longer_than_three.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b497520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|word|word_length|\n",
      "+----+-----------+\n",
      "|   t|          1|\n",
      "|   h|          1|\n",
      "|   e|          1|\n",
      "|   p|          1|\n",
      "|   r|          1|\n",
      "|   o|          1|\n",
      "|   j|          1|\n",
      "|   e|          1|\n",
      "|   c|          1|\n",
      "|   t|          1|\n",
      "+----+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_nonull.select(\n",
    "    col('word'),\n",
    "    length(col('word')).alias('word_length')\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac2a2f",
   "metadata": {},
   "source": [
    "## Exercise 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f520290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_stop_words = words_nonull.where(~col('word').isin(['is', 'not', 'the', 'if']))\n",
    "no_stop_words.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e3e1f",
   "metadata": {},
   "source": [
    "## Exercise 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35daca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    book = spark.read.text('../../data/gutenberg_books/1342-0.txt')\n",
    "    # book = book.printSchema() remove this line for the code to work\n",
    "    lines = book.select(split(book.value, ' ').alias('line'))\n",
    "    words = lines.select(explode(col('line')).alias('word'))\n",
    "except AnalysisException as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db98caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
